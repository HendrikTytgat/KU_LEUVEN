{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Pipeline: FIGRL test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this experiment can be downloaded through te following link:\n",
    "http://snap.stanford.edu/jodie/wikipedia.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Imbalance: 0.05% of all nodes in the dataset are banned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the pipeline for the Stanford Wikipedia dataset kicks off, some global parameters need to be defined. We devised a manual\n",
    "`kfold`-fold out-of-time validation, by dividing the dataset based on a rolling window approach. `timeframe`specifes which timeframe is selected. The `embedding_size`defines the dimension of the embeddings learned by Fast Inductive Graph Representation Learning algorithm. The `intermediate_dimension` is given by choosing an appropriate approximation ratio by the following formula: `intermediate_dimension` = max{4log(amount of nodes)/e^2, k/e^2} with e the approximation ratio and k the final embeddings_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters:\n",
    "kfold = 5\n",
    "timeframe = 2\n",
    "embedding_size = 10\n",
    "intermediate_dimension = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import dateparser\n",
    "import networkx as nx\n",
    "import stellargraph as sg\n",
    "import scipy\n",
    "from scipy.sparse import csr\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\hendr\\\\OneDrive\\\\Documents\\\\KU Leuven Job\\\\datasets\\\\reddit.csv\",header=None, skiprows=1)\n",
    "df = df.set_index(df.index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['user_id','item_id','timestamp','state_label']\n",
    "column_name.extend(range(4,176))\n",
    "df.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682448\n"
     ]
    }
   ],
   "source": [
    "df['user_id']+=max(df.index)+1\n",
    "df['item_id']+=max(df.user_id)+1\n",
    "print(min(df.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def split(x, n): \n",
    "#    split_list = []\n",
    "#    if(x < n):  \n",
    "#        print(-1) \n",
    "#    elif (x % n == 0): \n",
    "#        for i in range(n): \n",
    "#            split_list.append(x//n) \n",
    "#    else: \n",
    "#        zp = n - (x % n) \n",
    "#        pp = x//n \n",
    "#        for i in range(n): \n",
    "#            if(i>= zp): \n",
    "#                split_list.append(pp + 1) \n",
    "#            else: \n",
    "#                split_list.append(pp) \n",
    "#    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_list = split(672447,kfold)\n",
    "#split_list\n",
    "#k = 0\n",
    "#for i in range(0,kfold):\n",
    "#    k+=split_list[i]\n",
    "#    split_list[i]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin_id = split_list[timeframe-2]\n",
    "#end_id = split_list[timeframe-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_timeframe = df.iloc[begin_id:end_id,:]\n",
    "#cutoff = round(0.6*len(data_timeframe))\n",
    "#train_data = data_timeframe.head(cutoff)\n",
    "#inductive_data = data_timeframe.tail(len(data_timeframe)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = round(0.6*len(df))\n",
    "train_data = df.head(cutoff)\n",
    "inductive_data = df.tail(len(df)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of banned pages for the train data is:\n",
      " 0    403316\n",
      "1       152\n",
      "Name: state_label, dtype: int64\n",
      "The distribution of banned pages for the inductive data is:\n",
      " 0    268765\n",
      "1       214\n",
      "Name: state_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The distribution of banned pages for the train data is:\\n', train_data['state_label'].value_counts())\n",
    "print('The distribution of banned pages for the inductive data is:\\n', inductive_data['state_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_rate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An undersampling rate of  0.1 is applied.\n",
      "The new distribution for the train set is:\n",
      " 0    1520\n",
      "1     152\n",
      "Name: state_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "if not undersampling_rate is None:\n",
    "    print(\"An undersampling rate of \", undersampling_rate, \"is applied.\")\n",
    "    train_data['index'] = train_data.index\n",
    "    undersample = RandomUnderSampler(sampling_strategy=(undersampling_rate))\n",
    "    X, y = undersample.fit_resample(train_data, train_data['state_label'])\n",
    "    train_data = X.set_index(X['index']).drop('index',axis=1)\n",
    "    print('The new distribution for the train set is:\\n', train_data[\"state_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct the Graph Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A networkx graph is constructed with edit, user and webpage nodes. Creating a three partite graph. The FI-GRL framework derives embeddings starting from an adjacency matrix that it constructs using the graph's edgelist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"edit\":train_data.index, \"user\":train_data.user_id, \"webpage\":train_data.item_id}\n",
    "edges = [zip(train_data.user_id, train_data.index),zip(train_data.item_id, train_data.index)]\n",
    "g_nx = nx.Graph()\n",
    "for key, values in nodes.items():\n",
    "            g_nx.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            g_nx.add_edges_from(edge)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_data['index'] = train_data.index\n",
    "inductive_data['index'] = inductive_data.index\n",
    "inductive_graph_data = pd.concat((train_data,inductive_data))\n",
    "inductive_graph_data = inductive_graph_data.set_index(inductive_graph_data['index']).drop(\"index\",axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train FIGRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep the original indices after concatenating the train and inductive data, because they represent the transaction node ids. We need to concatenate these dataframes in order to easily construct the new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_data['index'] = train_data.index\n",
    "inductive_data['index'] = inductive_data.index\n",
    "inductive_graph_data = pd.concat((train_data,inductive_data))\n",
    "inductive_graph_data = inductive_graph_data.set_index(inductive_graph_data['index']).drop(\"index\",axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FI-GRL, a fast inductive graph representation framework is trained using the aforeconstructed graph. This algorithm is implemented in matlab so we make use of matlab.engine to deploy its native implementation. First, we instantiate the FI-GRL class with the intermediate dimension of the matrix between the input graph and the embedding space, in addition to the size of final dimension (embedding space). FI-GRL's train step returns three matrices: U, which represents the embedding space, sigma and v, which are matrices that will be used in the inductive step to generate embeddings for unseen nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3453, 3453)\n"
     ]
    }
   ],
   "source": [
    "A = nx.adjacency_matrix(g_nx)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6857702732086182\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "n,m = A.shape\n",
    "diags = A.sum(axis=1).flatten()\n",
    "D = scipy.sparse.spdiags(diags, [0], n, n, format='csr')\n",
    "#L = D - A\n",
    "with scipy.errstate(divide='ignore'):\n",
    "   diags_sqrt = 1.0/np.lib.scimath.sqrt(diags)\n",
    "diags_sqrt[np.isinf(diags_sqrt)] = 0\n",
    "DH = scipy.sparse.spdiags(diags_sqrt, [0], n, n, format='csr')\n",
    "\n",
    "Normalized_random_walk = DH.dot(A.dot(DH))\n",
    "\n",
    "S = np.random.randn(n, intermediate_dimension) / np.sqrt(intermediate_dimension)\n",
    "\n",
    "#S = np.array(pd.read_csv('S_train_matrix.csv', header=None))\n",
    "\n",
    "C = Normalized_random_walk.dot(S)\n",
    "\n",
    "np.savetxt(\"S_train_matrix.csv\", S, delimiter=\",\")\n",
    "\n",
    "from scipy import sparse\n",
    "sC = sparse.csr_matrix(C)\n",
    "\n",
    "U, sigma, V = scipy.sparse.linalg.svds(sC, k=embedding_size, tol=0,which='LM')\n",
    "V = V.transpose()\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "figrl_train_emb = pd.DataFrame(U)\n",
    "figrl_train_emb = figrl_train_emb.set_index(figrl_train_emb.index)\n",
    "figrl_train_emb = figrl_train_emb.loc[train_data.index]\n",
    "sigma = np.array(sigma)\n",
    "V = np.array(V)\n",
    "S = np.array(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inductive Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"edit\":inductive_graph_data.index, \"user\":inductive_graph_data.user_id, \"webpage\":inductive_graph_data.item_id}\n",
    "edges = [zip(inductive_graph_data.user_id, inductive_graph_data.index),zip(inductive_graph_data.item_id, inductive_graph_data.index)]\n",
    "graph_full = nx.Graph()\n",
    "\n",
    "for key, values in nodes.items():\n",
    "            graph_full.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            graph_full.add_edges_from(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New inductive S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S = np.random.randn(max(inductive_graph_data.item_id)+1, intermediate_dimension) / np.sqrt(intermediate_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "inductive_dict = {}\n",
    "for node in inductive_data.index:\n",
    "    user = inductive_data.loc[node].user_id\n",
    "    item = inductive_data.loc[node].item_id\n",
    "    inductive_dict[node] = [user,item]\n",
    "inductive_dict = collections.OrderedDict(sorted(inductive_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = nx.degree(graph_full)\n",
    "train_degrees = dict(degrees)\n",
    "train_degrees = collections.OrderedDict(sorted(train_degrees.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "def get_vector(inductive_dict, max_id):\n",
    "    print(\"creating sparse vector matrix\")\n",
    "    row  = []\n",
    "    col  = []\n",
    "    data = []\n",
    "    i = 0\n",
    "    for node, v in inductive_dict.items():\n",
    "        for n in v:\n",
    "            if n is not None:\n",
    "                row.append(i)\n",
    "                col.append(n)\n",
    "                if n > max_id:\n",
    "                    max_id = int(n)\n",
    "                #calculate value\n",
    "                inductive_degree = len([x for x in v if x != None])\n",
    "                value = 1/np.sqrt(inductive_degree)\n",
    "                value = value * (1/np.sqrt(train_degrees[n]))\n",
    "                data.append(value)\n",
    "        i+=1\n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    data = np.array(data)\n",
    "    return coo_matrix((data, (row, col)), shape=(len(inductive_dict), max_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sparse vector matrix\n",
      "2.5902349948883057\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "v = get_vector(inductive_dict, max(inductive_graph_data.item_id))\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53562331199646\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "t0 = time.time()\n",
    "inductive_degrees = []\n",
    "\n",
    "#altijd 2 (onderstaand)\n",
    "for l in inductive_dict.values():\n",
    "    x = 0\n",
    "    for i in l:\n",
    "        if i is not None:\n",
    "            x+=1\n",
    "    inductive_degrees.append(x)\n",
    "    \n",
    "def sqrt_d_inv(inductive_degrees):\n",
    "        sqrt_d_inv = np.array([1/np.sqrt(degree)  if degree > 0 else 0 for degree in inductive_degrees])\n",
    "        return scipy.sparse.spdiags(sqrt_d_inv,0, sqrt_d_inv.size, sqrt_d_inv.size)\n",
    "sqrt_d_inv = sqrt_d_inv(inductive_degrees)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.403291940689087\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "p = v.dot(S)\n",
    "U =(p.dot(V)).dot(np.linalg.inv(sigma))\n",
    "U = sqrt_d_inv.dot(U)\n",
    "t1 = time.time()\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "figrl_inductive_emb = pd.DataFrame(U, index=inductive_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['state_label']\n",
    "figrl_train_emb = pd.merge(figrl_train_emb, train_data.loc[figrl_train_emb.index].drop('state_label', axis=1), left_index=True, right_index=True)\n",
    "figrl_inductive_emb = pd.merge(figrl_inductive_emb, inductive_data.loc[figrl_inductive_emb.index].drop('state_label', axis=1), left_index=True, right_index=True)\n",
    "\n",
    "baseline_train = train_data.drop('state_label', axis=1)\n",
    "baseline_inductive = inductive_data.drop('state_label', axis=1)\n",
    "\n",
    "classifier.fit(baseline_train, train_labels)\n",
    "baseline_predictions = classifier.predict_proba(baseline_inductive)\n",
    "    \n",
    "classifier.fit(figrl_train_emb, train_labels)\n",
    "predictions = classifier.predict_proba(figrl_inductive_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def pr_curve(probabilities, labels, name):\n",
    "\n",
    "        \"\"\"\n",
    "        This function plots the precision recall curve for the used classification model and a majority classifier.\n",
    "        \n",
    "        \"\"\"\n",
    "        probs = probabilities[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(labels, probs)\n",
    "        pyplot.plot(recall, precision, label=name)\n",
    "        # axis labels\n",
    "        pyplot.xlabel('Recall')\n",
    "        pyplot.ylabel('Precision')\n",
    "        # show the legend\n",
    "        pyplot.legend()\n",
    "        \n",
    "        print('Average precision-recall score for ', name, ' configuration XGBoost: {0:0.10f}'.format(average_precision_score(labels, probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score for  FI-GRL  configuration XGBoost: 0.0015730254\n",
      "Average precision-recall score for  Baseline  configuration XGBoost: 0.0015730254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\events.py:88: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inductive_labels = df.loc[figrl_inductive_emb.index]['state_label']\n",
    "\n",
    "pr_curve(predictions, inductive_labels, \"FI-GRL\")\n",
    "\n",
    "pr_curve(baseline_predictions, inductive_labels, \"Baseline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
