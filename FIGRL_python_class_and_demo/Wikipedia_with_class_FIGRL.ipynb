{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Pipeline: FIGRL test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the pipeline for the Stanford Wikipedia dataset kicks off, some global parameters need to be defined. We devised a manual\n",
    "`kfold`-fold out-of-time validation, by dividing the dataset based on a rolling window approach. `timeframe`specifes which timeframe is selected. The `embedding_size`defines the dimension of the embeddings learned by Fast Inductive Graph Representation Learning algorithm. The `intermediate_dimension` is given by choosing an appropriate approximation ratio by the following formula: `intermediate_dimension` = max{4log(amount of nodes)/e^2, k/e^2} with e the approximation ratio and k the final embeddings_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters:\n",
    "kfold = 5\n",
    "timeframe = 2\n",
    "embedding_size = 40\n",
    "intermediate_dimension = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import dateparser\n",
    "import networkx as nx\n",
    "import scipy\n",
    "from scipy.sparse import csr\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\hendr\\\\OneDrive\\\\Documents\\\\KU Leuven Job\\\\datasets\\\\wikipedia.csv\",header=None, skiprows=1)\n",
    "df = df.set_index(df.index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['user_id','item_id','timestamp','state_label']\n",
    "column_name.extend(range(4,176))\n",
    "df.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165702\n"
     ]
    }
   ],
   "source": [
    "df['user_id']+=max(df.index)+1\n",
    "df['item_id']+=max(df.user_id)+1\n",
    "print(min(df.item_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def split(x, n): \n",
    "    split_list = []\n",
    "    if(x < n):  \n",
    "        print(-1) \n",
    "    elif (x % n == 0): \n",
    "        for i in range(n): \n",
    "            split_list.append(x//n) \n",
    "    else: \n",
    "        zp = n - (x % n) \n",
    "        pp = x//n \n",
    "        for i in range(n): \n",
    "            if(i>= zp): \n",
    "                split_list.append(pp + 1) \n",
    "            else: \n",
    "                split_list.append(pp) \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_list = split(672447,kfold)\n",
    "split_list\n",
    "k = 0\n",
    "for i in range(0,kfold):\n",
    "    k+=split_list[i]\n",
    "    split_list[i]=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "begin_id = split_list[timeframe-2]\n",
    "end_id = split_list[timeframe-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_timeframe = df.iloc[begin_id:end_id,:]\n",
    "cutoff = round(0.6*len(data_timeframe))\n",
    "train_data = data_timeframe.head(cutoff)\n",
    "inductive_data = data_timeframe.tail(len(data_timeframe)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = round(0.6*len(df))\n",
    "train_data = df.head(cutoff)\n",
    "inductive_data = df.tail(len(df)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of banned pages for the train data is:\n",
      " 0    94349\n",
      "1      135\n",
      "Name: state_label, dtype: int64\n",
      "The distribution of banned pages for the inductive data is:\n",
      " 0    62908\n",
      "1       82\n",
      "Name: state_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The distribution of banned pages for the train data is:\\n', train_data['state_label'].value_counts())\n",
    "print('The distribution of banned pages for the inductive data is:\\n', inductive_data['state_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling_rate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "if not undersampling_rate is None:\n",
    "    print(\"An undersampling rate of \", undersampling_rate, \"is applied.\")\n",
    "    train_data['index'] = train_data.index\n",
    "    undersample = RandomUnderSampler(sampling_strategy=(undersampling_rate))\n",
    "    X, y = undersample.fit_resample(train_data, train_data['state_label'])\n",
    "    train_data = X.set_index(X['index']).drop('index',axis=1)\n",
    "    print('The new distribution for the train set is:\\n', train_data[\"state_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct the Graph Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A networkx graph is constructed with edit, user and webpage nodes. Creating a three partite graph. The FI-GRL framework derives embeddings starting from an adjacency matrix that it constructs using the graph's edgelist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"edit\":train_data.index, \"user\":train_data.user_id, \"webpage\":train_data.item_id}\n",
    "edges = [zip(train_data.user_id, train_data.index),zip(train_data.item_id, train_data.index)]\n",
    "g_nx = nx.Graph()\n",
    "for key, values in nodes.items():\n",
    "            g_nx.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            g_nx.add_edges_from(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train FIGRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FI-GRL, a fast inductive graph representation framework is trained using the aforeconstructed graph. This algorithm is implemented in matlab so we make use of matlab.engine to deploy its native implementation. First, we instantiate the FI-GRL class with the intermediate dimension of the matrix between the input graph and the embedding space, in addition to the size of final dimension (embedding space). FI-GRL's train step returns three matrices: U, which represents the embedding space, sigma and v, which are matrices that will be used in the inductive step to generate embeddings for unseen nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FIGRL import FIGRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "figrl = FIGRL(embedding_size, intermediate_dimension)\n",
    "figrl_train_emb = figrl.train(g_nx)\n",
    "figrl_train_emb = figrl_train_emb.loc[train_data.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inductive Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "inductive_graph_data = pd.concat((train_data,inductive_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"edit\":inductive_graph_data.index, \"user\":inductive_graph_data.user_id, \"webpage\":inductive_graph_data.item_id}\n",
    "edges = [zip(inductive_graph_data.user_id, inductive_graph_data.index),zip(inductive_graph_data.item_id, inductive_graph_data.index)]\n",
    "graph_full = nx.Graph()\n",
    "\n",
    "for key, values in nodes.items():\n",
    "            graph_full.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            graph_full.add_edges_from(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "inductive_dict = {}\n",
    "for node in inductive_data.index:\n",
    "    user = inductive_data.loc[node].user_id\n",
    "    item = inductive_data.loc[node].item_id\n",
    "    inductive_dict[node] = [user,item]\n",
    "inductive_dict = collections.OrderedDict(sorted(inductive_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sparse vector matrix\n"
     ]
    }
   ],
   "source": [
    "figrl_inductive_emb = figrl.inductive_step(graph_full, inductive_dict, max(inductive_graph_data.item_id), inductive_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>94485</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94486</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000397</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94487</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94488</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.001119</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.000569</td>\n",
       "      <td>-0.001507</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94489</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.000219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157470</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001332</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157471</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157472</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000397</td>\n",
       "      <td>-0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157473</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157474</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000397</td>\n",
       "      <td>-0.000249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62990 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "94485   0.000341  0.000791  0.001113  0.000434  0.000255 -0.001020  0.000003   \n",
       "94486   0.000129  0.000074 -0.000199 -0.000276  0.000325  0.000313  0.000093   \n",
       "94487   0.000087  0.001248 -0.000025  0.000515  0.001128  0.000284 -0.000065   \n",
       "94488   0.000300  0.000324 -0.001119  0.000454  0.000444  0.000774  0.000576   \n",
       "94489   0.000203 -0.000700  0.000397  0.000902  0.000042  0.000404  0.000054   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "157470  0.000519  0.001350  0.000264 -0.000934  0.000273  0.001328  0.000435   \n",
       "157471 -0.000716  0.000274 -0.000184 -0.000618  0.000219  0.000218  0.000447   \n",
       "157472  0.000310  0.000650  0.000288 -0.000488 -0.000030  0.000624  0.001157   \n",
       "157473  0.000016  0.001195 -0.000125  0.000079 -0.000121 -0.000557  0.000192   \n",
       "157474  0.000310  0.000650  0.000288 -0.000488 -0.000030  0.000624  0.001157   \n",
       "\n",
       "              7         8         9   ...        30        31        32  \\\n",
       "94485   0.000216 -0.000992 -0.000103  ... -0.000361 -0.001476 -0.000302   \n",
       "94486   0.000189 -0.000574 -0.000285  ...  0.000101 -0.000397  0.000174   \n",
       "94487   0.000508 -0.000142  0.000764  ... -0.000266 -0.000803 -0.001470   \n",
       "94488   0.000072  0.000056  0.000797  ...  0.000289 -0.000569 -0.001507   \n",
       "94489   0.000184  0.000863  0.001251  ... -0.000202 -0.001061 -0.000553   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "157470  0.000162 -0.000038 -0.000711  ... -0.001332 -0.000765 -0.001204   \n",
       "157471  0.000720 -0.000578 -0.000852  ... -0.000115 -0.000235 -0.000334   \n",
       "157472 -0.000647 -0.000140  0.000928  ...  0.000284 -0.000730  0.000794   \n",
       "157473  0.001236  0.000572  0.000261  ... -0.000214  0.001244 -0.000703   \n",
       "157474 -0.000647 -0.000140  0.000928  ...  0.000284 -0.000730  0.000794   \n",
       "\n",
       "              33        34        35        36        37        38        39  \n",
       "94485  -0.000377 -0.000907 -0.000660 -0.000990  0.000205  0.000612  0.001445  \n",
       "94486   0.000448 -0.000257  0.000857 -0.000749  0.000048 -0.000102 -0.000097  \n",
       "94487   0.000194 -0.000757 -0.000032  0.000117  0.000242 -0.000919  0.000610  \n",
       "94488  -0.000222  0.000052 -0.000282 -0.000035 -0.000223  0.000949  0.000362  \n",
       "94489   0.000494 -0.000077 -0.000380  0.000151  0.000282 -0.000291  0.000219  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "157470 -0.000215 -0.001053 -0.000814 -0.000666  0.000232  0.000471  0.000866  \n",
       "157471  0.000067  0.001409 -0.000549  0.000199  0.000697 -0.000425  0.000696  \n",
       "157472 -0.000154  0.000235  0.000464  0.000269  0.000068 -0.000397 -0.000249  \n",
       "157473 -0.000377 -0.001977  0.000996 -0.000344  0.000563  0.000453  0.001369  \n",
       "157474 -0.000154  0.000235  0.000464  0.000269  0.000068 -0.000397 -0.000249  \n",
       "\n",
       "[62990 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figrl_inductive_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['state_label']\n",
    "figrl_train_emb = pd.merge(figrl_train_emb, train_data.loc[figrl_train_emb.index].drop('state_label', axis=1), left_index=True, right_index=True)\n",
    "figrl_inductive_emb = pd.merge(figrl_inductive_emb, inductive_data.loc[figrl_inductive_emb.index].drop('state_label', axis=1), left_index=True, right_index=True)\n",
    "\n",
    "baseline_train = train_data.drop('state_label', axis=1)\n",
    "baseline_inductive = inductive_data.drop('state_label', axis=1)\n",
    "\n",
    "classifier.fit(baseline_train, train_labels)\n",
    "baseline_predictions = classifier.predict_proba(baseline_inductive)\n",
    "    \n",
    "classifier.fit(figrl_train_emb, train_labels)\n",
    "predictions = classifier.predict_proba(figrl_inductive_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def pr_curve(probabilities, labels, name):\n",
    "\n",
    "        \"\"\"\n",
    "        This function plots the precision recall curve for the used classification model and a majority classifier.\n",
    "        \n",
    "        \"\"\"\n",
    "        probs = probabilities[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(labels, probs)\n",
    "        pyplot.plot(recall, precision, label=name)\n",
    "        # axis labels\n",
    "        pyplot.xlabel('Recall')\n",
    "        pyplot.ylabel('Precision')\n",
    "        # show the legend\n",
    "        pyplot.legend()\n",
    "        \n",
    "        print('Average precision-recall score for ', name, ' configuration XGBoost: {0:0.10f}'.format(average_precision_score(labels, probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score for  FI-GRL  configuration XGBoost: 0.0377795219\n",
      "Average precision-recall score for  Baseline  configuration XGBoost: 0.0214397362\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inductive_labels = df.loc[figrl_inductive_emb.index]['state_label']\n",
    "\n",
    "pr_curve(predictions, inductive_labels, \"FI-GRL\")\n",
    "\n",
    "pr_curve(baseline_predictions, inductive_labels, \"Baseline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
